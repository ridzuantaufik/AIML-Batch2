{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c4bc666-34a1-47b6-8018-1ad79dafae95",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #add8e6; padding: 10px; height: 70px; border-radius: 15px;\">\n",
    "    <div style=\"font-family: 'Georgia', serif; font-size: 20px; padding: 10px; text-align: right; position: absolute; right: 20px;\">\n",
    "        Mohammad Idrees Bhat <br>\n",
    "        <span style=\"font-family: 'Arial', sans-serif;font-size: 12px; color: #0a0a0a;\">Tech Skills Trainer | AI/ML Consultant</span> <!--- Mohammad Idrees Bhat | Tech Skills Trainer | AI/ML Consultant --->\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef444d2e-97e9-49a8-bf3d-0119a2dfebb5",
   "metadata": {},
   "source": [
    "<!--- Mohammad Idrees Bhat | Tech Skills Trainer | AI/ML Consultant --->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151ad3d8-0bce-4e29-86da-5ea91b5a69df",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #002147; padding: 10px; text-align: center; color: white; font-size: 32px; font-family: 'Arial', sans-serif;\">\n",
    "    Building Neural Networks <br>\n",
    "    <h3 style=\"text-align: center; color: white; font-size: 15px; font-family: 'Arial', sans-serif;\">Constructing and training neural networks</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155e8ec7-547b-41f4-b6f6-6e6e719c198c",
   "metadata": {},
   "source": [
    "<div style=\"background-color: white; color: black; padding: 10px;\">\n",
    "    <h4><b>AGENDA</b> <p><p>\n",
    "1.  Neural Networks<p><p> \n",
    "2.  Creating a Neural network\n",
    "</h4> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b1c30b-e766-4658-8d70-1b0af10ae2f4",
   "metadata": {},
   "source": [
    "<!-- Link the Montserrat font -->\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=Montserrat:wght@700&display=swap\" rel=\"stylesheet\">\n",
    "\n",
    "<!-- Main div with centered content and a flexible box size, no scroll bar -->\n",
    "<div style=\"background-color: #baf733; min-height: 100px; width: 100%; display: flex; justify-content: center; align-items: center; position: relative; padding: 20px; box-sizing: border-box; font-family: 'Montserrat', sans-serif; font-weight: 700; font-size: 20px; border-radius: 15px;\">\n",
    "    <div style=\"position: absolute; top: 10px; right: 10px; padding: 5px 10px; font-size: 14px; color: rgba(0, 0, 0, 0.05); border-radius: 10px;\">Mohammad Idrees Bhat</div>\n",
    "    <!-- Fill the below text with question -->\n",
    "    <!-- Fill the below text with question -->\n",
    "    If you could have dinner with any historical figure, who would it be and why?\n",
    "    <!-- Fill the above text with question -->\n",
    "    <!-- Fill the above text with question -->\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ec8637",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightgreen; color: black; padding: 4px;\">\n",
    "    <h3>1. Neural Networks\n",
    "</h3> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aef031-1416-4707-b2a0-fc60ca4ee7ca",
   "metadata": {},
   "source": [
    "- Intro to Neural Networks by 3B1B [What are Neural Networks](https://www.3blue1brown.com/lessons/neural-networks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b086158c",
   "metadata": {},
   "source": [
    "### What is a Neural Network?\n",
    "\n",
    "A **neural network** is a computational model inspired by the way biological neural networks in the human brain process information. It consists of layers of nodes (also known as neurons), where each node in a layer is connected to every node in the previous and next layers.\n",
    "\n",
    "The primary goal of a neural network is to learn a mapping from inputs to outputs by adjusting the weights of the connections between neurons based on the data.\n",
    "\n",
    "Let's start with a simple neural network!\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ee3009",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; color: black; padding: 4px;\">\n",
    "    <h4> Understanding the Structure of a Neural Network\n",
    "</h4> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11b40ca",
   "metadata": {},
   "source": [
    "A neural network consists of three types of layers:\n",
    "\n",
    "- **Input Layer**: The layer where the data is fed into the network. It corresponds to the features of the data.\n",
    "- **Hidden Layers**: Intermediate layers between the input and output layers. These layers perform computations using weights and activation functions.\n",
    "- **Output Layer**: The final layer that produces the network's predictions. For binary classification, it usually has a sigmoid activation function, which outputs a value between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376183fa",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; color: black; padding: 4px;\">\n",
    "    <h4> How Does a Neural Network Learn?\n",
    "</h4> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4f791b",
   "metadata": {},
   "source": [
    "Neural networks learn by adjusting their **weights**. Initially, these weights are random, and the network's output is inaccurate. The learning process involves training the network using data to minimize the **loss function**.\n",
    "\n",
    "The learning algorithm that neural networks use is called **Backpropagation**. Here's a high-level overview of the process:\n",
    "\n",
    "1. **Forward Propagation**: The input data passes through the network, from the input layer to the output layer, making predictions.\n",
    "2. **Calculate Loss**: The prediction is compared with the actual target (the true label), and the error (loss) is calculated.\n",
    "3. **Backpropagation**: The loss is propagated backward through the network, adjusting the weights of the connections to reduce the error.\n",
    "4. **Optimization**: The weights are updated using an optimization algorithm (e.g., **Gradient Descent**).\n",
    "\n",
    "The network repeats this process multiple times over many epochs until the loss is minimized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4bd259",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; color: black; padding: 4px;\">\n",
    "    <h4> Activation Functions\n",
    "</h4> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce47c8b3",
   "metadata": {},
   "source": [
    "Activation functions are mathematical functions used in the hidden and output layers of a neural network to introduce non-linearity. They help the model learn complex patterns.\n",
    "\n",
    "### Common Activation Functions:\n",
    "- **ReLU (Rectified Linear Unit)**: Most commonly used in hidden layers. It outputs the input directly if it’s positive; otherwise, it outputs zero.\n",
    "  \n",
    "\n",
    "- **Sigmoid**: Used in the output layer for binary classification. It maps values to a range between 0 and 1.\n",
    "\n",
    "\n",
    "- **Tanh**: Similar to sigmoid but maps values to the range between -1 and 1.\n",
    "\n",
    "### Why Non-Linearity?\n",
    "\n",
    "Without non-linearity (activation functions), a neural network would just be a linear model, no matter how many layers it has. Activation functions allow the network to learn complex, non-linear relationships in data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1722bab8",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; color: black; padding: 4px;\">\n",
    "    <h4> Building Our First Neural Network with Keras\n",
    "</h4> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1c755a",
   "metadata": {},
   "source": [
    "**TensorFlow** is an open-source deep learning framework developed by Google. \n",
    "\n",
    "- https://www.tensorflow.org\n",
    "\n",
    "It provides a set of tools to build and train machine learning models, particularly those involving neural networks. \n",
    "\n",
    "Think of TensorFlow as a \"workbench\" for creating, training, and deploying models.\n",
    "\n",
    "TensorFlow gets its name from the term \"**tensor**\", which refers to the multi-dimensional arrays (like matrices or higher-dimensional structures) that are used to represent data in machine learning. \n",
    "\n",
    "**Flow** refers to the way data moves through the various operations (or layers) of a model, forming a \"**computational graph.**\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc27b6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213c5ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb43442",
   "metadata": {},
   "source": [
    "**What is happening in the model part?**\n",
    "\n",
    "- **Flatten**: Converts the 2D image (28x28) into a 1D list (784 values).\n",
    "- **Dense (128 neurons)**: Tries to learn the patterns in the image with 128 \"neurons.\"\n",
    "- **Dropout**: Helps avoid overfitting by randomly ignoring some neurons during training.\n",
    "- **Dense (10 neurons)**: Decides which digit (0-9) the image represents, with each neuron representing a digit and the highest probability being the chosen one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079cf482",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "` tf.keras.layers.Flatten(input_shape=(28, 28)),`\n",
    "\n",
    "- Flatten is like \"unfolding\" or \"stretching\" the 28x28 images into a straight line.\n",
    "- A 28x28 image has 28 rows and 28 columns of pixels. When we use the flatten layer, we take all those 784 pixels (28 * 28 = 784) and make them into a single row of 784 values.\n",
    "- This is needed because a Dense layer (next layer) only accepts 1D input (a list of numbers, not a 2D matrix).\n",
    "\n",
    "`tf.keras.layers.Dense(128, activation='relu'),`\n",
    "\n",
    "- This is a Dense layer, meaning every pixel in the input (784 numbers) is connected to 128 neurons in this layer. Each neuron processes the input in its own way and gives an output.\n",
    "- Think of this layer as having 128 \"neurons\" that each try to understand the image in their own way, making it learn complex patterns and features like edges, shapes, etc.\n",
    "- ReLU (Rectified Linear Unit) is an activation function. \n",
    "\n",
    "    It just means that if the neuron’s output is negative, it becomes zero (this helps the model learn faster and avoid overfitting). \n",
    "\n",
    "    If it’s positive, the output stays the same. It’s like saying \"if you’re not positive enough, you get nothing.\"\n",
    "\n",
    " `tf.keras.layers.Dropout(0.2),`\n",
    "\n",
    "- This is a Dropout layer, and it’s a trick used during training to help the model learn better.\n",
    "- During each step of training, it randomly \"turns off\" 20% of the neurons (0.2 means 20%).\n",
    "- This prevents the model from becoming too reliant on any one neuron and forces it to learn more general patterns, making it less likely to overfit (become too specific to the training data).\n",
    "- It’s like a student who studies by forcing themselves to learn everything, not just relying on one method.\n",
    "\n",
    "`tf.keras.layers.Dense(10, activation='softmax')`\n",
    "\n",
    "- This is the output layer, where the final decision happens.\n",
    "- It has 10 neurons because there are 10 possible digit classes (0 through 9) in the MNIST dataset. Each neuron in this layer corresponds to one digit.\n",
    "- Softmax is an activation function used here, and it converts the output of these 10 neurons into probabilities (values between 0 and 1) that sum up to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274de9b7",
   "metadata": {},
   "source": [
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e799c8",
   "metadata": {},
   "source": [
    "**Keras** is a high-level neural network API, written in Python. \n",
    "\n",
    "It is designed to simplify the process of building deep learning models by providing an easy-to-use interface. \n",
    "\n",
    "Keras allows you to define neural networks with just a few lines of code, abstracting away many of the complexities involved in using lower-level libraries like TensorFlow.\n",
    "\n",
    "Think of Keras as the user-friendly interface or the \"wrapper\" around TensorFlow. It makes it easier to experiment and prototype with deep learning models.\n",
    "\n",
    "Here’s another analogy:\n",
    "\n",
    "Keras is like a remote control for the TensorFlow toolbox. It makes it simpler to use TensorFlow’s power without dealing with all the fine details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2224f3c3",
   "metadata": {},
   "source": [
    "#### **How do TensorFlow and Keras come together:**\n",
    "\n",
    "- **Building the Model**: You use Keras to define the layers and architecture of your neural network (input, hidden, output layers).\n",
    "- **Training the Model**: When you call methods like model.fit(), Keras takes care of the details, but under the hood, TensorFlow is handling the data flow and optimization processes.\n",
    "- **Evaluation and Prediction**: After training, you can use Keras to evaluate the model's performance or make predictions, again leveraging TensorFlow's efficient computation engine.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d500bdc",
   "metadata": {},
   "source": [
    "Now that we have the basic understanding of neural networks, let's build a simple one using **Keras**.\n",
    "\n",
    "We'll use the **Sequential** model, which is a linear stack of layers.\n",
    "\n",
    "### Steps:\n",
    "1. **Import necessary libraries**.\n",
    "2. **Prepare the data** (split into training and testing sets).\n",
    "3. **Build the model** (define input, hidden, and output layers).\n",
    "4. **Compile the model** (set optimizer, loss function, and metrics).\n",
    "5. **Train the model**.\n",
    "6. **Evaluate the model**.\n",
    "\n",
    "Let’s start by building and training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b580c8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c881c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate a simple binary classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(X_train.shape[1],)),  # Input layer\n",
    "    Dense(8, activation='relu'),                                   # Hidden layer\n",
    "    Dense(1, activation='sigmoid')                                  # Output layer (binary classification)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff12bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4400ae4d",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; color: black; padding: 4px;\">\n",
    "    <h4> Visualizing Model Performance\n",
    "</h4> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f0489f",
   "metadata": {},
   "source": [
    "To understand how the model is performing over time, let's plot the **training** and **validation** loss and accuracy across epochs.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1316101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6027d108",
   "metadata": {},
   "source": [
    "- Training Accuracy Line: Represents how well the model is doing on the training dataset after each epoch.\n",
    "- Validation Accuracy Line: Represents how well the model is doing on the validation dataset, which is separate data used to test the model during training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a790f25",
   "metadata": {},
   "source": [
    "Evaluating the graph:\n",
    "\n",
    "- Training and validation lines should follow similar trends.\n",
    "Both should rise and plateau, with training accuracy slightly higher.\n",
    "- Validation accuracy should not diverge too much from training accuracy.\n",
    "A small gap is normal, but a large gap suggests overfitting.\n",
    "- If validation accuracy plateaus early, consider tuning hyperparameters.\n",
    "This might involve changing the learning rate, adding layers, or modifying the model architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe77cb1b",
   "metadata": {},
   "source": [
    "**Insights for Graph Interpretations:**\n",
    "\n",
    "1. **Healthy Graph**: Training and validation lines rise together, with training slightly above validation, both stabilizing at similar values. The model learns effectively and generalizes well without significant overfitting or underfitting.\n",
    "\n",
    "2. **Overfitting**: Training accuracy increases sharply, nearing 100%, while validation accuracy plateaus or declines, indicating the model is memorizing the training data. Address this with regularization, more data, or simplifying the model.\n",
    "\n",
    "3. **Underfitting**: Both accuracies remain low and close together, showing the model is too simple or undertrained to capture patterns. Fix this by increasing model complexity, training longer, or reducing regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d1a6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ed77e2",
   "metadata": {},
   "source": [
    "**Explanation for Loss vs. Epoch Graphs:**\n",
    "\n",
    "1. **Healthy Graph**: Training and validation loss decrease together, staying close. Indicates effective learning and good generalization without overfitting or underfitting.\n",
    "\n",
    "2. **Overfitting**: Training loss drops steadily, but validation loss plateaus or increases. Suggests memorization of training data. Mitigate with regularization, early stopping, or simpler models.\n",
    "\n",
    "3. **Underfitting**: Both losses remain high and decrease very slowly. Implies the model is too simple or inadequately trained. Address by adding complexity, training longer, or improving data preprocessing.\n",
    "\n",
    "4. **Validation Loss Fluctuates**: Training loss decreases, but validation loss oscillates. May result from noise or insufficient validation data. Use larger datasets or techniques like data augmentation to stabilize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6789a59",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; color: black; padding: 4px;\">\n",
    "    <h4> Making Predictions with the Trained Model\n",
    "</h4> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5bd3d1",
   "metadata": {},
   "source": [
    "Now that the model is trained, we can use it to make predictions on new, unseen data. Let’s see how to predict the class labels for our test data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea074c59",
   "metadata": {},
   "source": [
    "**Loss** measures the \"error\" in predictions, guiding the model during training to improve its performance. It acts as the foundation for optimizing weights and ensuring the model learns meaningful patterns from the data.\n",
    "\n",
    "`model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])`\n",
    "\n",
    "- loss function is setup when the model is compiled\n",
    "- `sparse_categorical_crossentropy` is used for multi-class classification problems. \n",
    "- we can use various other loss functions too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2a0cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X, y)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1b6ccd",
   "metadata": {},
   "source": [
    "### **Loss Functions in Deep Learning**\n",
    "\n",
    "\n",
    "- **`sparse_categorical_crossentropy`**: For multi-class classification with integer labels; calculates the cross-entropy between true labels and predicted probabilities.  \n",
    "- **`categorical_crossentropy`**: For multi-class classification with one-hot encoded labels; computes cross-entropy for each class.  \n",
    "- **`binary_crossentropy`**: For binary classification; measures the log loss for two classes.  \n",
    "- **`mean_squared_error` (MSE)**: For regression; computes the squared difference between predicted and true values.  \n",
    "- **`mean_absolute_error` (MAE)**: For regression; computes the absolute difference between predictions and targets.  \n",
    "- **`huber_loss`**: For regression; combines MSE and MAE, robust to outliers.  \n",
    "- **`mean_absolute_percentage_error` (MAPE)**: For regression; calculates the percentage difference between predictions and actual values.  \n",
    "- **`hinge`**: For binary classification with labels -1 and 1; used in SVMs, penalizes misclassified samples.  \n",
    "- **`squared_hinge`**: Variation of hinge loss; penalizes the square of hinge loss for misclassifications.  \n",
    "- **`poisson`**: For count-based data; computes the Poisson deviance between true and predicted values.  \n",
    "- **`cosine_similarity`**: Measures the cosine similarity between true and predicted vectors; useful for directional data.  \n",
    "- **`log_cosh`**: For regression; similar to MSE but less sensitive to large errors.  \n",
    "- **`kullback_leibler_divergence` (KLD)**: Measures divergence between two probability distributions, true and predicted.  \n",
    "- **`custom_loss`**: User-defined function tailored to specific requirements in a model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cec2eb",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; color: black; padding: 4px;\">\n",
    "    <h4> Download the trained model\n",
    "</h4> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30262f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "model.save(\"tf_intro_trained_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b044107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuse the same model to make predictions\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model(\"tf_intro_trained_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab710e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the loaded model\n",
    "test_loss, test_accuracy = loaded_model.evaluate(X_test, y_test)\n",
    "print(f\"Loaded Model Test Loss: {test_loss}\")\n",
    "print(f\"Loaded Model Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b712d7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with the loaded model\n",
    "predictions = loaded_model.predict(X_test[:5])\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8215955b",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightgreen; color: black; padding: 4px;\">\n",
    "    <h3>2. Create your own Neural Networks\n",
    "</h3> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d594e2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b><font size=\"5\"> Live Exercise</font> </b>\n",
    "    <h3>\n",
    "    Let's create a <b>Neural Network</b> and apply it on the dataset we used earlier, to <b>Predict Customer Churn</b>\n",
    "    </h3>\n",
    "</div>\n",
    "\n",
    "<!--- Mohammad Idrees Bhat | Tech Skills Trainer | AI/ML Consultant --->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7493b3",
   "metadata": {},
   "source": [
    "**1. Start with importing libraries and dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fbe899",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas numpy tensorflow scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a4824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install kagglehub # if kagglehub is not installed yet\n",
    "#import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "#path = kagglehub.dataset_download(\"blastchar/telco-customer-churn\")\n",
    "\n",
    "#print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7620c457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "# Use the path to get to the dataset\n",
    "# Rename the dataset and choose the right path\n",
    "\n",
    "# Load the dataset (assuming you have downloaded the dataset as a CSV)\n",
    "data = pd.read_csv('c:\\\\Users\\\\devid\\\\.cache\\\\kagglehub\\\\datasets\\\\blastchar\\\\telco-customer-churn\\\\versions\\\\1\\\\Telco-Customer-Churn.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb82a635",
   "metadata": {},
   "source": [
    "2. **Data Cleaning**\n",
    "- We can check for missing values and handle them if needed\n",
    "- We need to turn catagorical values into numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a61b6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the dataset\n",
    "# Drop unnecessary columns (e.g., customerID)\n",
    "data = data.drop(columns=['customerID'])\n",
    "\n",
    "# Handle missing or invalid values\n",
    "# Convert 'TotalCharges' to numeric, replacing errors with NaN\n",
    "data['TotalCharges'] = pd.to_numeric(data['TotalCharges'], errors='coerce')\n",
    "data = data.dropna()  # Drop rows with NaN values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4155791",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info() # check what kind of data there is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45ce563",
   "metadata": {},
   "source": [
    "- **Encode Categorical Features**\n",
    "- Categorical features need to be encoded into numerical values. You can use OneHotEncoder for this task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97827476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "categorical_columns = ['gender', 'Partner', 'Dependents', 'PhoneService', \n",
    "                       'MultipleLines', 'InternetService', 'OnlineSecurity',\n",
    "                       'DeviceProtection', 'TechSupport', 'StreamingTV',\n",
    "                       'StreamingMovies', 'Contract', 'PaperlessBilling', \n",
    "                       'PaymentMethod', 'Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e6fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply label encoding to categorical columns\n",
    "encoder = LabelEncoder()\n",
    "for col in categorical_columns:\n",
    "    data[col] = encoder.fit_transform(data[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85517b0f",
   "metadata": {},
   "source": [
    "**Select the target feature**\n",
    "- standardize the numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2b1ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = data.drop(columns=['Churn'])  # Features\n",
    "y = data['Churn']                 # Target (Churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf44768f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize numeric columns\n",
    "scaler = StandardScaler()\n",
    "numeric_columns = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "X[numeric_columns] = scaler.fit_transform(X[numeric_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb2d178",
   "metadata": {},
   "source": [
    "\n",
    "**3. Train test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a2f127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5060bc56",
   "metadata": {},
   "source": [
    "**4. Create a Neural Network:**\n",
    "\n",
    "A simple 3-layer neural network with two hidden layers:\n",
    "- 16 neurons in the first hidden layer.\n",
    "- 8 neurons in the second hidden layer.\n",
    "\n",
    "Output layer uses the sigmoid activation function for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e7341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple neural network\n",
    "model = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(19,)),  # Input layer\n",
    "    Dense(8, activation='relu'),                                   # Hidden layer\n",
    "    Dense(1, activation='sigmoid')                                # Output layer (binary classification)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d4ffac",
   "metadata": {},
   "source": [
    "You specified `input_shape=(19,)` because this is the number of features (columns) in your training data X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4823a9b2",
   "metadata": {},
   "source": [
    "**5. Training the model:**\n",
    "- Trained the model for 10 epochs with a batch size of 32.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d404aab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9954a6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85bf6e4",
   "metadata": {},
   "source": [
    "### **We got an error**\n",
    "Let's debug this issue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbb9f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.dtypes)  # Check if any column in X_train is non-numeric\n",
    "print(y_train.dtypes)  # Check if y_train is non-numeric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31be83a2",
   "metadata": {},
   "source": [
    "If any column in X_train or the target y_train contains strings, it needs to be converted. But we can see that there are not strings. \n",
    "\n",
    "It's clear that the column OnlineBackup is still an object, meaning it contains string values that need to be encoded to numerical values for the neural network to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75987ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode 'OnlineBackup' column\n",
    "encoder = LabelEncoder()\n",
    "data['OnlineBackup'] = encoder.fit_transform(data['OnlineBackup'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bf8ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.dtypes)  # All columns should now be numeric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeb6231",
   "metadata": {},
   "source": [
    "**Proceed with training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c273bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5806fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for non-numeric columns (any column that isn't of type 'number')\n",
    "non_numeric_columns = X_train.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "print(\"Non-numeric columns:\")\n",
    "print(non_numeric_columns)\n",
    "\n",
    "# Check if any non-numeric values exist in the dataset\n",
    "non_numeric_rows = X_train[non_numeric_columns]\n",
    "print(\"\\nNon-numeric values:\")\n",
    "print(non_numeric_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bc3255",
   "metadata": {},
   "source": [
    "It looks like the OnlineBackup column contains non-numeric values like 'No', 'Yes', and 'No internet service'. These need to be converted into numeric values for the neural network to process them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7978a0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop('OnlineBackup', axis=1)\n",
    "X_train = X_train.drop('InternetService', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b558126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.dtypes)  # All columns should now be numeric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbafbe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5d9fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)  # Check the number of columns (should be 18 now)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee98bd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(17,)),  # Adjusted to 17 features\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9383ae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.dtypes)  # Check the data types of all columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b396d9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.isnull().sum())  # Check for missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ac5f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c3cf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5ad14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model file\n",
    "model.save(\"churn_prediction_trained_model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a112b4",
   "metadata": {},
   "source": [
    "**6.  Evaluation:**\n",
    "- Let's monitor performance now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46b1242",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, batch_size=32)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980eaacb",
   "metadata": {},
   "source": [
    "**There is another error, seems like the columns from earlier are persisting in test dataset too. Let's fix this:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72af75f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f860511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop multiple columns\n",
    "X_test = X_test.drop(['InternetService', 'OnlineBackup'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77789577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for accuracy\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, batch_size=32)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5706972",
   "metadata": {},
   "source": [
    "**Optional step: Make Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa91f9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions (model outputs probabilities for class 1)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Convert probabilities to binary predictions (0 or 1)\n",
    "predictions = (predictions > 0.5).astype(int)\n",
    "# This comparison checks if the predicted probability for class 1 is greater than 0.5. If it is, the output is True (1), else False (0).\n",
    "# .astype(int): Converts the boolean True/False values into 1/0 for final binary classification.\n",
    "\n",
    "\n",
    "# If you want the predictions in a more readable format\n",
    "print(predictions[:10])  # Print first 10 predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d1ac86",
   "metadata": {},
   "source": [
    "Additional Resources:\n",
    "\n",
    "- https://www.freecodecamp.org/news/building-a-neural-network-from-scratch\n",
    "- Excellent introduction to Neural Networks by G. Sanderson: https://youtu.be/aircAruvnKk "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ed7ea-1940-434d-bb2d-601d07994783",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; color: white; padding: 10px; text-align: center;\">\n",
    "    <h1>_________________________________END________________________________\n",
    "        <!--- Mohammad Idrees Bhat | Tech Skills Trainer | AI/ML Consultant --->\n",
    "</h1> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e86481-eae2-4019-9515-66a43a30f0fb",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #002147; color: #fff; padding: 30px; text-align: center;\">\n",
    "    <h1>THANK YOU!\n",
    "        <!--- Mohammad Idrees Bhat | Tech Skills Trainer | AI/ML Consultant --->\n",
    "</h1> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefa2f04-f141-405d-8a9f-8cf186d66f41",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightgreen; color: black; padding: 30px;\">\n",
    "    <h4> Live Exercise Solutions\n",
    "        \n",
    "</h4> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f2d487-56ef-4c22-a1c9-d25e9df33e37",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"  padding: 10px; text-align: center;\">\n",
    "    <font size=\"3\"> Programming Interveiw Questions</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e08c3f-3e5b-46a6-9fbb-456cbd850553",
   "metadata": {},
   "source": [
    "1. topic:\n",
    "    - question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5454f2e3-4fa4-48f9-936a-35be52d769af",
   "metadata": {},
   "source": [
    "<!--- Mohammad Idrees Bhat | Mohammad Idrees Bhat --->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e92ba4c-672c-4e9f-b842-2b2d9234e5ff",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color: #ffe4e1; color: #2f4f4f; padding: 10px; border-radius: 10px; width: 350px; text-align: center; float: right; margin: 20px 0;\">\n",
    "    Mohammad Idrees Bhat<br>\n",
    "    <span style=\"font-size: 12px; color: #696969;\">\n",
    "        Tech Skills Trainer | AI/ML Consultant\n",
    "    </span>\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cc27b3-58d0-431e-8121-f1b4c08377c7",
   "metadata": {},
   "source": [
    "<!--- Mohammad Idrees Bhat | Tech Skills Trainer | AI/ML Consultant --->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
